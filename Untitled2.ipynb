{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28852,"status":"ok","timestamp":1659816324242,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"},"user_tz":-270},"id":"06HgOMSkBj3N","outputId":"88d56ea2-07a6-474f-d4c2-385a4e539523"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/models/MA\n","/content/drive/MyDrive/models/MA\n","Sat Aug  6 20:05:24 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/models/MA/'\n","!pwd\n","!nvidia-smi"]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import vision_transformer as vits\n","teacher = vits.__dict__['vit_base'](patch_size=16)\n","teacher.load_state_dict(torch.load('/content/drive/MyDrive/models/dino-main/clipVitB16.pth'))\n","ourClip = nn.Sequential(\n","    teacher,\n","    nn.ReLU(),\n","    nn.Linear(in_features=768,out_features=512),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(512,512),\n","    # nn.ReLU(),\n","    # nn.Linear(in_features=768,out_features=512),\n","    nn.Softmax(dim=1)\n","\n",")"],"metadata":{"id":"ZfPoqfZ1HWea","executionInfo":{"status":"ok","timestamp":1659816722800,"user_tz":-270,"elapsed":1742,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["ourClip.state_dict().keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzUGZNJKx9bb","executionInfo":{"status":"ok","timestamp":1659816744805,"user_tz":-270,"elapsed":773,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}},"outputId":"68b95c97-719f-475b-f28b-e03b33bd97a7"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['0.cls_token', '0.pos_embed', '0.patch_embed.proj.weight', '0.patch_embed.proj.bias', '0.blocks.0.norm1.weight', '0.blocks.0.norm1.bias', '0.blocks.0.attn.qkv.weight', '0.blocks.0.attn.qkv.bias', '0.blocks.0.attn.proj.weight', '0.blocks.0.attn.proj.bias', '0.blocks.0.norm2.weight', '0.blocks.0.norm2.bias', '0.blocks.0.mlp.fc1.weight', '0.blocks.0.mlp.fc1.bias', '0.blocks.0.mlp.fc2.weight', '0.blocks.0.mlp.fc2.bias', '0.blocks.1.norm1.weight', '0.blocks.1.norm1.bias', '0.blocks.1.attn.qkv.weight', '0.blocks.1.attn.qkv.bias', '0.blocks.1.attn.proj.weight', '0.blocks.1.attn.proj.bias', '0.blocks.1.norm2.weight', '0.blocks.1.norm2.bias', '0.blocks.1.mlp.fc1.weight', '0.blocks.1.mlp.fc1.bias', '0.blocks.1.mlp.fc2.weight', '0.blocks.1.mlp.fc2.bias', '0.blocks.2.norm1.weight', '0.blocks.2.norm1.bias', '0.blocks.2.attn.qkv.weight', '0.blocks.2.attn.qkv.bias', '0.blocks.2.attn.proj.weight', '0.blocks.2.attn.proj.bias', '0.blocks.2.norm2.weight', '0.blocks.2.norm2.bias', '0.blocks.2.mlp.fc1.weight', '0.blocks.2.mlp.fc1.bias', '0.blocks.2.mlp.fc2.weight', '0.blocks.2.mlp.fc2.bias', '0.blocks.3.norm1.weight', '0.blocks.3.norm1.bias', '0.blocks.3.attn.qkv.weight', '0.blocks.3.attn.qkv.bias', '0.blocks.3.attn.proj.weight', '0.blocks.3.attn.proj.bias', '0.blocks.3.norm2.weight', '0.blocks.3.norm2.bias', '0.blocks.3.mlp.fc1.weight', '0.blocks.3.mlp.fc1.bias', '0.blocks.3.mlp.fc2.weight', '0.blocks.3.mlp.fc2.bias', '0.blocks.4.norm1.weight', '0.blocks.4.norm1.bias', '0.blocks.4.attn.qkv.weight', '0.blocks.4.attn.qkv.bias', '0.blocks.4.attn.proj.weight', '0.blocks.4.attn.proj.bias', '0.blocks.4.norm2.weight', '0.blocks.4.norm2.bias', '0.blocks.4.mlp.fc1.weight', '0.blocks.4.mlp.fc1.bias', '0.blocks.4.mlp.fc2.weight', '0.blocks.4.mlp.fc2.bias', '0.blocks.5.norm1.weight', '0.blocks.5.norm1.bias', '0.blocks.5.attn.qkv.weight', '0.blocks.5.attn.qkv.bias', '0.blocks.5.attn.proj.weight', '0.blocks.5.attn.proj.bias', '0.blocks.5.norm2.weight', '0.blocks.5.norm2.bias', '0.blocks.5.mlp.fc1.weight', '0.blocks.5.mlp.fc1.bias', '0.blocks.5.mlp.fc2.weight', '0.blocks.5.mlp.fc2.bias', '0.blocks.6.norm1.weight', '0.blocks.6.norm1.bias', '0.blocks.6.attn.qkv.weight', '0.blocks.6.attn.qkv.bias', '0.blocks.6.attn.proj.weight', '0.blocks.6.attn.proj.bias', '0.blocks.6.norm2.weight', '0.blocks.6.norm2.bias', '0.blocks.6.mlp.fc1.weight', '0.blocks.6.mlp.fc1.bias', '0.blocks.6.mlp.fc2.weight', '0.blocks.6.mlp.fc2.bias', '0.blocks.7.norm1.weight', '0.blocks.7.norm1.bias', '0.blocks.7.attn.qkv.weight', '0.blocks.7.attn.qkv.bias', '0.blocks.7.attn.proj.weight', '0.blocks.7.attn.proj.bias', '0.blocks.7.norm2.weight', '0.blocks.7.norm2.bias', '0.blocks.7.mlp.fc1.weight', '0.blocks.7.mlp.fc1.bias', '0.blocks.7.mlp.fc2.weight', '0.blocks.7.mlp.fc2.bias', '0.blocks.8.norm1.weight', '0.blocks.8.norm1.bias', '0.blocks.8.attn.qkv.weight', '0.blocks.8.attn.qkv.bias', '0.blocks.8.attn.proj.weight', '0.blocks.8.attn.proj.bias', '0.blocks.8.norm2.weight', '0.blocks.8.norm2.bias', '0.blocks.8.mlp.fc1.weight', '0.blocks.8.mlp.fc1.bias', '0.blocks.8.mlp.fc2.weight', '0.blocks.8.mlp.fc2.bias', '0.blocks.9.norm1.weight', '0.blocks.9.norm1.bias', '0.blocks.9.attn.qkv.weight', '0.blocks.9.attn.qkv.bias', '0.blocks.9.attn.proj.weight', '0.blocks.9.attn.proj.bias', '0.blocks.9.norm2.weight', '0.blocks.9.norm2.bias', '0.blocks.9.mlp.fc1.weight', '0.blocks.9.mlp.fc1.bias', '0.blocks.9.mlp.fc2.weight', '0.blocks.9.mlp.fc2.bias', '0.blocks.10.norm1.weight', '0.blocks.10.norm1.bias', '0.blocks.10.attn.qkv.weight', '0.blocks.10.attn.qkv.bias', '0.blocks.10.attn.proj.weight', '0.blocks.10.attn.proj.bias', '0.blocks.10.norm2.weight', '0.blocks.10.norm2.bias', '0.blocks.10.mlp.fc1.weight', '0.blocks.10.mlp.fc1.bias', '0.blocks.10.mlp.fc2.weight', '0.blocks.10.mlp.fc2.bias', '0.blocks.11.norm1.weight', '0.blocks.11.norm1.bias', '0.blocks.11.attn.qkv.weight', '0.blocks.11.attn.qkv.bias', '0.blocks.11.attn.proj.weight', '0.blocks.11.attn.proj.bias', '0.blocks.11.norm2.weight', '0.blocks.11.norm2.bias', '0.blocks.11.mlp.fc1.weight', '0.blocks.11.mlp.fc1.bias', '0.blocks.11.mlp.fc2.weight', '0.blocks.11.mlp.fc2.bias', '0.norm.weight', '0.norm.bias', '2.weight', '2.bias', '5.weight', '5.bias'])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0iK_qGdBn2j","outputId":"c43e4568-62e6-406d-e713-126620ebce96"},"outputs":[{"output_type":"stream","name":"stdout","text":["['s6', 's4', 's3', 's5', 's2', 's0', 's1']\n","=> 7011\n","/content/drive/MyDrive/models/MA/bracs/se_resnet_MsLoss_1.9938.pth\n"]}],"source":["import numpy as np\n","import os\n","import torch\n","import sys\n","from ABE_M_model import ABE_M\n","from my_model import se_resnet50\n","from resnet import resnet50\n","from dataset import SingleData\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","\n","\n","def get_data_list(data_path):\n","    img_list = []\n","    for root, dirs, files in os.walk(data_path):\n","        if files == []:\n","            class_name = dirs\n","        elif dirs == []:\n","            for f in files:\n","                img_path = os.path.join(root, f)\n","                img_list.append(img_path)\n","    return class_name, img_list\n","\n","\n","def test(test_loader, model, devicei):\n","    with torch.no_grad():\n","        model.eval()\n","        embedding_vec = []\n","        #test_img_list = []\n","        for batch_idx, (data, target, img_name) in enumerate(test_loader):\n","            data = data.to(device)\n","            outputs = model(data)\n","            outputs=[outputs]\n","            #print(type(img_name)) \n","            if batch_idx == 0:\n","                for i in range(len(outputs)):\n","                    output = outputs[i].cpu().numpy()\n","                    embedding_vec.append(output)\n","                labels = np.array(target)\n","                test_img_list = img_name\n","            else:\n","                for i in range(len(outputs)):\n","                    output = outputs[i].cpu().numpy()\n","                    embedding_vec[i] = np.concatenate((embedding_vec[i], output))\n","                labels = np.concatenate((labels, np.array(target)))\n","                test_img_list += img_name\n","    return embedding_vec, labels, list(test_img_list)\n","\n","\n","def Accuracy(embedding_vec, labels, test_img_list):\n","    print(len(embedding_vec[0]))\n","    def _get_sim_matrix(embedding_vec, num_vec):\n","        sim_matrix = np.zeros((num_vec, num_vec))\n","        for i in range(len(embedding_vec)):\n","            sim_matrix += np.matmul(embedding_vec[i], embedding_vec[i].T)\n","        if len(embedding_vec) > 1:\n","            sim_matrix = sim_matrix / len(embedding_vec)\n","        return sim_matrix\n","    #k_list = [1,2,4,8]\n","    k_list = [1]\n","    max_k = max(k_list)\n","    num_vec = embedding_vec[0].shape[0]\n","    print('total num of test image: {}'.format(num_vec))\n","    sim_mat = _get_sim_matrix(embedding_vec, num_vec)\n","    result = np.zeros((num_vec, max_k+1))\n","    \n","    #f = open('result.txt', 'w')\n","    \n","    for i in range(num_vec):\n","        temp_index = np.argsort(-1*sim_mat[i])[:max_k+1]\n","        for j in range(max_k+1):\n","            result[i][j] = labels[temp_index[j]]\n","            #f.write(test_img_list[i]+' '+test_img_list[temp_index[j]]+' '+str(sim_mat[i][temp_index[j]])+'\\n')\n","    #f.close() \n","    predicts = result[:,1]\n","    n_p = sum(labels==predicts)/num_vec\n","    num_class = len(set(labels))\n","    cnf_mat = np.zeros((num_class, num_class))\n","    for i in range(len(labels)):\n","        cnf_mat[int(labels[i])][int(predicts[i])] += 1\n","\n","    #np.save('./model/cnf_mat.npy', cnf_mat)\n","\n","    e = cnf_mat.diagonal()\n","    n_w = (e/cnf_mat.sum(axis=1)).mean()\n","    n_total = n_w*n_p\n","    accuracy = [(n_p,'np'), (n_w, 'nw'), (n_total, 'n_total')]\n","    '''\n","    recall = []\n","    for k in k_list:\n","        total = 0\n","        for i in range(num_vec):\n","            temp_list = result[i][1:k+1].tolist()\n","            if labels[i] in temp_list:\n","                total += 1\n","        recall.append((total/num_vec, k))\n","        print('Recall@k:{:.4f}, k={}'.format(total/num_vec, k))\n","    '''\n","    return accuracy \n","\n","\n","if __name__ == '__main__':\n","    # arg_len = len(sys.argv)\n","    # if arg_len != 2:\n","    #     raise Exception(\"Invalid argvs!\")\n","    # weight_folder = sys.argv[1]\n","    weight_folder = '/content/drive/MyDrive/models/MA/bracs/'\n","    model_name = 'se_resnet'\n","    #weight_type = weight_folder.split('/')[-1]\n","\n","    model_dict = {'ABE_M':ABE_M, 'se_resnet':se_resnet50, 'resnet50':resnet50}\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    batch_size = 128\n","    #num_learner = 4\n","    \n","           \n","    #data\n","    transform = transforms.Compose([\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor()\n","        ])\n","\n","    data_path = '/content/drive/MyDrive/datasets/bracs_test'\n","    class_name, img_list = get_data_list(data_path)\n","    test_dataset = SingleData(class_name, img_list, transform)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    print(\"=>\",len(test_dataloader.dataset.img_list))\n","    f = open(weight_folder+model_name+'_'+'results.txt', 'w')\n","    \n","    sorted_weight_file = os.listdir(weight_folder)\n","   \n","    sorted_weight_file.sort()\n","    for weight_f in sorted_weight_file:\n","        if weight_f[-3:] != 'pth' or model_name not in weight_f:\n","            continue\n","        weight_path = os.path.join(weight_folder, weight_f)\n","        print(weight_path)\n","\n","        # model = model_dict[model_name]() #####################################\n","        model=ourClip\n","        model.load_state_dict(torch.load(weight_path))\n","        model.to(device)\n","\n","\n","        embedding_vec, labels, test_img_list = test(test_dataloader, model, device)\n","        #print(test_img_list)\n","        accuracy_his = Accuracy(embedding_vec, labels, test_img_list)\n","        print(accuracy_his)\n","        f.write(weight_f + str(accuracy_his)+'\\n')\n","\n","    f.close()\n"]},{"cell_type":"code","source":["import os\n","data_path = '/content/drive/MyDrive/datasets/bracs_test/s5'\n","files=os.listdir(data_path)\n","len(files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdNRnPXBSpNn","executionInfo":{"status":"ok","timestamp":1659758157473,"user_tz":-270,"elapsed":458,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}},"outputId":"853fd93f-7188-4fae-f774-59dc2a45d781"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1001"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_54kAXvkU98y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"36005e06-7c68-4686-976b-7b35f89e12b9"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["['s1', 's2', 's3']\n","<dataset.SingleData object at 0x7f47248358d0>\n","/content/drive/MyDrive/models/MA/bcnb/se_resnet_MsLoss_2.1499.pth\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n","  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"]}],"source":["5import numpy as np\n","import os\n","import torch\n","import sys\n","from ABE_M_model import ABE_M\n","from my_model import se_resnet50\n","from resnet import resnet50\n","from dataset import SingleData\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","\n","\n","def get_data_list(data_path):\n","    img_list = []\n","    for root, dirs, files in os.walk(data_path):\n","        if files == []:\n","            class_name = dirs\n","        elif dirs == []:\n","            for f in files:\n","                img_path = os.path.join(root, f)\n","                img_list.append(img_path)\n","    return class_name, img_list\n","\n","\n","def test(test_loader, model, devicei):\n","    with torch.no_grad():\n","        model.eval()\n","        embedding_vec = []\n","        #test_img_list = []\n","        for batch_idx, (data, target, img_name) in enumerate(test_loader):\n","            data = data.to(device)\n","            outputs = model(data)\n","            #print(type(img_name)) \n","            if batch_idx == 0:\n","                for i in range(len(outputs)):\n","                    output = outputs[i].cpu().numpy()\n","                    embedding_vec.append(output)\n","                labels = np.array(target)\n","                test_img_list = img_name\n","            else:\n","                for i in range(len(outputs)):\n","                    output = outputs[i].cpu().numpy()\n","                    embedding_vec[i] = np.concatenate((embedding_vec[i], output))\n","                labels = np.concatenate((labels, np.array(target)))\n","                test_img_list += img_name\n","    return embedding_vec, labels, list(test_img_list)\n","\n","\n","def Accuracy(embedding_vec, labels, test_img_list):\n","    print(labels)\n","    def _get_sim_matrix(embedding_vec, num_vec):\n","        sim_matrix = np.zeros((num_vec, num_vec))\n","        for i in range(len(embedding_vec)):\n","            sim_matrix += np.matmul(embedding_vec[i], embedding_vec[i].T)\n","        if len(embedding_vec) > 1:\n","            sim_matrix = sim_matrix / len(embedding_vec)\n","        return sim_matrix\n","    #k_list = [1,2,4,8]\n","    k_list = [1]\n","    max_k = max(k_list)\n","    num_vec = embedding_vec[0].shape[0]\n","    print('total num of test image: {}'.format(num_vec))\n","    sim_mat = _get_sim_matrix(embedding_vec, num_vec)\n","    result = np.zeros((num_vec, max_k+1))\n","    for i in range(len(test_img_list)):\n","        for j in range(len(test_img_list)):\n","            index1=test_img_list[i].rfind('/')\n","            index2=test_img_list[j].rfind('/')\n","            idx1 = test_img_list[i].find('_', test_img_list[i].find('_') + 1)\n","            idx2 = test_img_list[j].find('_', test_img_list[j].find('_') + 1)\n","            if test_img_list[i][index1+1:idx1] == test_img_list[j][index2+1:idx2] and i!=j :\n","                sim_mat[i][j]=0\n","\n","    #f = open('result.txt', 'w')\n","    \n","    for i in range(num_vec):\n","        temp_index = np.argsort(-1*sim_mat[i])[:max_k+1]\n","        for j in range(max_k+1):\n","            result[i][j] = labels[temp_index[j]]\n","            #f.write(test_img_list[i]+' '+test_img_list[temp_index[j]]+' '+str(sim_mat[i][temp_index[j]])+'\\n')\n","    #f.close() \n","    predicts = result[:,1]\n","    n_p = sum(labels==predicts)/num_vec\n","    num_class = len(set(labels))\n","    cnf_mat = np.zeros((num_class, num_class))\n","    for i in range(len(labels)):\n","        cnf_mat[int(labels[i])][int(predicts[i])] += 1\n","\n","    #np.save('./model/cnf_mat.npy', cnf_mat)\n","\n","    e = cnf_mat.diagonal()\n","    n_w = (e/cnf_mat.sum(axis=1)).mean()\n","    n_total = n_w*n_p\n","    accuracy = [(n_p,'np'), (n_w, 'nw'), (n_total, 'n_total')]\n","    '''\n","    recall = []\n","    for k in k_list:\n","        total = 0\n","        for i in range(num_vec):\n","            temp_list = result[i][1:k+1].tolist()\n","            if labels[i] in temp_list:\n","                total += 1\n","        recall.append((total/num_vec, k))\n","        print('Recall@k:{:.4f}, k={}'.format(total/num_vec, k))\n","    '''\n","    return accuracy \n","\n","\n","if __name__ == '__main__':\n","    # arg_len = len(sys.argv)\n","    # if arg_len != 2:\n","    #     raise Exception(\"Invalid argvs!\")\n","    # weight_folder = sys.argv[1]\n","    weight_folder = '/content/drive/MyDrive/models/MA/bcnb/'\n","    model_name = 'se_resnet'\n","    #weight_type = weight_folder.split('/')[-1]\n","\n","    model_dict = {'ABE_M':ABE_M, 'se_resnet':se_resnet50, 'resnet50':resnet50}\n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    batch_size = 32\n","    #num_learner = 4\n","    \n","           \n","    #data\n","    transform = transforms.Compose([\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor()\n","        ])\n","\n","    data_path = '/content/drive/MyDrive/datasets/test_BCNB'\n","    class_name, img_list = get_data_list(data_path)\n","    test_dataset = SingleData(class_name, img_list, transform)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    print(test_dataset)\n","    f = open(weight_folder+model_name+'_'+'results-withtask.txt', 'w')\n","    \n","    sorted_weight_file = os.listdir(weight_folder)\n","   \n","    sorted_weight_file.sort()\n","    for weight_f in sorted_weight_file:\n","        if weight_f[-3:] != 'pth' or model_name not in weight_f:\n","            continue\n","        weight_path = os.path.join(weight_folder, weight_f)\n","        print(weight_path)\n","\n","        model = model_dict[model_name]() #####################################\n","        model.load_state_dict(torch.load(weight_path))\n","        model.to(device)\n","\n","\n","        embedding_vec, labels, test_img_list = test(test_dataloader, model, device)\n","        #print(test_img_list)\n","        accuracy_his = Accuracy(embedding_vec, labels, test_img_list)\n","        print(accuracy_his)\n","        f.write(weight_f + str(accuracy_his)+'\\n')\n","\n","    f.close()\n"]},{"cell_type":"code","source":["a='s1_132_32rf.png'\n","idx = a.find('_', a.find('_') + 1)\n","idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jgofdwT7ZD2j","executionInfo":{"status":"ok","timestamp":1655297066791,"user_tz":-270,"elapsed":11,"user":{"displayName":"reza abbasi","userId":"16461171515024221393"}},"outputId":"0b56a7be-9433-49e0-9f10-28c30307baba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[""],"metadata":{"id":"h7p4R-flZLq3"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM/wirExBJVP+XzUIxL3/et"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}